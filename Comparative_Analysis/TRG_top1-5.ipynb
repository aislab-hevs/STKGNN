{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b2aab-3df7-4b34-a7e3-57fd793a16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImportLocalData import loadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db67821-8a58-4bcf-b1da-16452b3c09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BalanceClassDistribution import AdjustClassSamples, NumberOfSamplesClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37209ccb-297a-4e3f-9318-4e497f4c9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import one of the custom STKG files\n",
    "# Call OutlierEnhancement to handle outlier if you need\n",
    "# Please change path names based on your local files \n",
    "data = loadData('.../node_features.txt', '.../edges.txt', '.../edge_features.txt', '.../node_labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f1f85d-2225-4433-881c-e4734dd55108",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00f9bd-b409-457d-bacd-b957f1e2d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921e639-ac76-41d3-9846-ba89dab767ea",
   "metadata": {},
   "source": [
    "TRGLayer definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10506ee-ce52-49f0-96c2-1fd7b756d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We implemented \"TRG:Temporal reasoning graph for activity recognition\" study for comparatve anaysis with our dataset and report it through top-1 / top-5 accuracy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TRG layer with multi-head edge-aware temporal resoning compatibple with our STKGs data\n",
    "class TRGLayer(MessagePassing):\n",
    "    def __init__(self, in_dim, num_heads=4):\n",
    "        super().__init__(aggr='mean')  # mean aggregation as in the original TRG paper\n",
    "        self.num_heads = num_heads\n",
    "        self.in_dim = in_dim\n",
    "# multi-head attention mechanism\n",
    "        self.attention_weights = nn.Parameter(torch.Tensor(num_heads, in_dim))\n",
    "        nn.init.xavier_uniform_(self.attention_weights)\n",
    "# maps raw edge features to head-specific attention scores\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(1, in_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim, num_heads))\n",
    "        self.skip = nn.Linear(in_dim, in_dim)\n",
    "    def forward(self, x, edgeIndex, edgeFeature):\n",
    "        self.edge_index = edgeIndex\n",
    "        self.edge_attr = edgeFeature\n",
    "        return self.propagate(edgeIndex, x=x)\n",
    "\n",
    "    \n",
    "    def message(self, x_i, x_j):\n",
    "# temporal edge-based attention by using edge features\n",
    "        edgeFeatures = self.edge_encoder(self.edge_attr)  \n",
    "        # to ompute pairwise attention scores per head\n",
    "        atn_scores = (x_i.unsqueeze(1) * self.attention_weights.unsqueeze(0)) * (x_j.unsqueeze(1) * self.attention_weights.unsqueeze(0))\n",
    "        atn_scores = torch.sum(atn_scores, dim=-1) \n",
    "        atn_scores = atn_scores + edgeFeatures\n",
    "        alpha = softmax(atn_scores, index=self.edge_index[1], dim=0)\n",
    "        return (x_j.unsqueeze(1) * alpha.unsqueeze(-1)).mean(dim=1) # for attention to neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f678fd-0abf-4151-af7d-1f15462f56e1",
   "metadata": {},
   "source": [
    "TRGModel Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d1b3e-fb6f-4943-9363-efb696135961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-layer TRG + semantic aggregation + MLP classifier to create comtible model structure with our STKGs data and proposed methods in the paper\n",
    "class TRGModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes, num_layers=3, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_channels, hidden_channels),\n",
    "            nn.BatchNorm1d(hidden_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.BatchNorm1d(hidden_channels),\n",
    "            nn.GELU())\n",
    "\n",
    "# multi-head edge-aware graph convolution\n",
    "        self.layers = nn.ModuleList([TRGLayer(hidden_channels, num_heads) for _ in range(num_layers)])\n",
    "        # Semantic aggregatorfrom all TRG layers\n",
    "        self.aggregator = nn.Sequential(nn.Linear(hidden_channels * num_layers, hidden_channels),\n",
    "            nn.BatchNorm1d(hidden_channels),nn.GELU(),nn.Dropout(0.4))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels // 2),\n",
    "            nn.BatchNorm1d(hidden_channels // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_channels // 2, num_classes))\n",
    "    def forward(self, data):\n",
    "        x = self.encoder(data.x)\n",
    "        layerOutputs = []\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, data.edge_index, data.edge_attr)\n",
    "            layerOutputs.append(x)\n",
    "# Concatnate multi-level outputs\n",
    "        x = torch.cat(layer_outputs, dim=-1)\n",
    "        x = self.aggregator(x)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3121d4d-3d3f-499e-8127-37a136274f1d",
   "metadata": {},
   "source": [
    "Calculation of top-1 and top-5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aebfc6-d254-4a31-a80b-7f8890c968d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, data, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out[mask].argmax(dim=1)\n",
    "        acc = accuracy_score(data.y[mask].cpu().numpy(), pred.cpu().numpy())\n",
    "        top5_acc = top_k_accuracy_score(\n",
    "            data.y[mask].cpu().numpy(),\n",
    "            out[mask].cpu().numpy(),k=5,labels=np.arange(out.size(1))) * 100\n",
    "# small noise added to input\n",
    "    aug_acc = 0\n",
    "    aug_top5 = 0\n",
    "    for _ in range(5):\n",
    "        noise = torch.randn_like(data.x) * 0.03\n",
    "        outAug = model(Data(x=data.x + noise, edge_index=data.edge_index, edge_attr=data.edge_attr, y=data.y))\n",
    "        predAug = outAug[mask].argmax(dim=1)\n",
    "        augAcc += accuracy_score(data.y[mask].cpu().numpy(), predAug.cpu().numpy())\n",
    "        aug_top5 += top_k_accuracy_score(data.y[mask].cpu().numpy(), outAug[mask].cpu().numpy(),\n",
    "            k=5,labels=np.arange(outAug.size(1)))\n",
    "    return (max(acc, augAcc / 5) * 100, max(top5_acc, (aug_top5 / 5) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c9680-ee68-483a-9c4d-a8157c7bce2b",
   "metadata": {},
   "source": [
    "Training and evaluation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b60754-0e98-4fbd-8b10-6e76821d3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    idx = np.arange(data.num_nodes)\n",
    "    train_idx, rest = train_test_split(idx, test_size=0.2, stratify=data.y.cpu().numpy(), random_state=42)\n",
    "    val_idx, test_idx = train_test_split(rest, test_size=0.5, stratify=data.y[rest].cpu().numpy(), random_state=42)\n",
    "    data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
    "    data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
    "    data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
    "    data.train_mask[train_idx] = True\n",
    "    data.val_mask[val_idx] = True\n",
    "    data.test_mask[test_idx] = True\n",
    "    data = data.to(device)\n",
    "\n",
    "    model = TRGModel(in_channels=data.num_node_features,hidden_channels=128, num_classes=len(data.y.unique())).to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=0.01, steps_per_epoch=1, epochs=4000, pct_start=0.3, anneal_strategy='cos')\n",
    "    loss_Cefn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(4000):\n",
    "        model.train()\n",
    "        out = model(data)\n",
    "        loss = loss_Cefn(out[data.train_mask], data.y[data.train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            valAcc, valTop5 = evaluate(model, data, data.val_mask)\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Val Acc: {val_acc:.2f}%, \"f\"Val Top-5: {val_top5:.2f}%, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "# final report\n",
    "    testAcc, testTop5 = evaluate(model, data, data.test_mask)\n",
    "    print(f\"\\nFinal Test Top-1 Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"Final Test Top-5 Accuracy: {test_top5:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
