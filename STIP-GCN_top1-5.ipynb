{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8b2aab-3df7-4b34-a7e3-57fd793a16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImportLocalData import loadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db67821-8a58-4bcf-b1da-16452b3c09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BalanceClassDistribution import AdjustClassSamples, NumberOfSamplesClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37209ccb-297a-4e3f-9318-4e497f4c9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import one of the custom STKG files\n",
    "# Call BalanceClass... to handle outliers if you need\n",
    "# Please change path names based on your local files \n",
    "data = loadData('/home/gozde/GEREKLI_DOSYALAR/STKGNN_Codes_Data (4)/STKGNN_Codes_Data/STKG_ LocalData/MS-STKG-Medium/node_features.txt', '/home/gozde/GEREKLI_DOSYALAR/STKGNN_Codes_Data (4)/STKGNN_Codes_Data/STKG_ LocalData/MS-STKG-Medium/edges.txt', '/home/gozde/GEREKLI_DOSYALAR/STKGNN_Codes_Data (4)/STKGNN_Codes_Data/STKG_ LocalData/MS-STKG-Medium/edge_features.txt', '/home/gozde/GEREKLI_DOSYALAR/STKGNN_Codes_Data (4)/STKGNN_Codes_Data/STKG_ LocalData/MS-STKG-Medium/node_labels.txt')\n",
    "data = AdjustClassSamples(data) #this is optinal, yet in papr we used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed89ad-1125-4c1b-8285-103bc7c88069",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf6a60-0967-4c52-93a6-fcc2c76fae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "from torch_geometric.utils import subgraph, add_self_loops, degree\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921e639-ac76-41d3-9846-ba89dab767ea",
   "metadata": {},
   "source": [
    "STIP_GCN Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf94a2bd-396e-4e76-b1f9-493b92fc93fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We implemented \"STIP-GCN:Space-time interest points graph convolutional network for action recognition\" \n",
    "#study for comparatve anaysis with our dataset and report it through top-1 / top-5 accuracy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# STIP-GCN MODEL WHICH COMPATIBLE our STKGs daTaset\n",
    "class STIP_GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, edge_attr_dim):\n",
    "        super(STIP_GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # A small MLP to learn edge weights from edge features\n",
    "        self.edge_weight_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(edge_attr_dim, 1),\n",
    "            torch.nn.Sigmoid())\n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.dropout = Dropout(p=0.5)\n",
    "        self.alpha = torch.nn.Parameter(torch.tensor(0.5))  # Initialized at 0.5 for equal contribution\n",
    "\n",
    "    def forward(self, data):\n",
    "        learned_weight = self.edge_weight_net(data.edge_attr).squeeze()\n",
    "# Split edge features into coordinates of source and destination nodes\n",
    "        r_i = data.edge_attr[:, :3]  # Source node coordinates\n",
    "        r_j = data.edge_attr[:, 3:]  # Target node coordinates\n",
    "        h_i = data.x[data.edge_index[0]]\n",
    "        h_j = data.x[data.edge_index[1]]\n",
    "\n",
    "        cos_sim = F.cosine_similarity(h_i, h_j)\n",
    "        similarity = (cos_sim + 1) / 2\n",
    "# euclidean distance between of nodes\n",
    "        distance = torch.norm(r_i - r_j, p=2, dim=1)\n",
    "        distance = torch.exp(-distance)\n",
    "# structural weight using similarity and distance\n",
    "        structural_weight = similarity / distance\n",
    "# remove weights below the mean value\n",
    "        structural_weight = (structural_weight > structural_weight.mean()).float() * structural_weight\n",
    "        edge_w = self.alpha * learned_weight + (1 - self.alpha) * structural_weight\n",
    "        edge_in, edge_w = add_self_loops(data.edge_index, edge_w, num_nodes=data.num_nodes)\n",
    "# normalizon edge weights for spectral GCN\n",
    "        row, col = edge_in\n",
    "        deg = degree(row, data.num_nodes, dtype=data.x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * edge_w * deg_inv_sqrt[col]\n",
    "\n",
    "        x = F.relu(self.conv1(data.x, edge_in, norm))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x, edge_in, norm))\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374087f7-6183-477c-854a-bb6de4471ea3",
   "metadata": {},
   "source": [
    "Train Function Definition for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "402d1abf-49e3-4d5e-ab3e-f3f1cd5e328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, train_idx, val_idx, test_idx, model_name=\"STIP_GCNmodel\"):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    bestVal_acc = 0\n",
    "    bestVal_top5 = 0\n",
    "    bestModel_state = None\n",
    "\n",
    "    for epoch in range(200):  # Number of epoch defined based on paper\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out[train_idx], data.y[train_idx])\n",
    "        if torch.isnan(loss):\n",
    "            print(\"NaN loss detected!\")\n",
    "            break\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        # Evaluation every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                outEval = model(data)\n",
    "                pred = outEval.argmax(dim=1)\n",
    "# Top-1 and Top-5 acuracy for training and valdation sets\n",
    "                train_acc = accuracy_score(data.y[train_idx].cpu().numpy(), pred[train_idx].cpu().numpy())\n",
    "                train_top5 = top_k_accuracy_score(\n",
    "                    data.y[train_idx].cpu().numpy(),outEval[train_idx].cpu().numpy(), k=5,labels=np.arange(outEval.size(1)))\n",
    "                val_acc = accuracy_score(data.y[val_idx].cpu().numpy(), pred[val_idx].cpu().numpy())\n",
    "                val_top5 = top_k_accuracy_score(data.y[val_idx].cpu().numpy(),\n",
    "                    outEval[val_idx].cpu().numpy(),k=5,\n",
    "                    labels=np.arange(outEval.size(1)))\n",
    "                if val_acc > bestVal_acc:\n",
    "                    bestVal_acc = val_acc\n",
    "                    bestVal_top5 = val_top5\n",
    "                    bestModel_state = model.state_dict()\n",
    "\n",
    "                print(f'Model: {model_name}, Epoch: {epoch+1}, Loss: {loss.item():.4f}, 'f'Train Acc: {train_acc:.4f}, Train Top-5: {train_top5:.4f}, 'f'Val Acc: {val_acc:.4f}, Val Top-5: {val_top5:.4f}')\n",
    "\n",
    "    if bestModel_state is not None:\n",
    "        model.load_state_dict(bestModel_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outTest = model(data)\n",
    "        predTest = outTest.argmax(dim=1)\n",
    "        test_acc = accuracy_score(data.y[test_idx].cpu().numpy(), predTest[test_idx].cpu().numpy())\n",
    "        test_top5 = top_k_accuracy_score(data.y[test_idx].cpu().numpy(),\n",
    "            outTest[test_idx].cpu().numpy(),k=5,labels=np.arange(outTest.size(1)))\n",
    "\n",
    "    print(f'\\nSTIP_GCN Moel: {model_name}, Final Test Top-1 Acuracy: {test_acc*100:.2f}%')\n",
    "    print(f'STIP_GCN Model: {model_name}, Final Test Top-5 Accuracy: {test_top5*100:.2f}%')\n",
    "\n",
    "    return test_acc, test_top5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f6451-f480-4ac4-bfc2-43d77afea7dc",
   "metadata": {},
   "source": [
    "Evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a2657-3da7-49d4-a49f-c43574df8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = data.to(device)\n",
    "    scaler = StandardScaler()\n",
    "    data.x = scaler.fit_transform(data.x.cpu().numpy())\n",
    "    data.x = torch.tensor(data.x, dtype=torch.float).to(device)\n",
    "\n",
    "# Split dataset into 80% train, 10% validation, 10% test by stratfied sampling\n",
    "    indices = np.arange(data.num_nodes)\n",
    "    train_idx, test_val_idx = train_test_split(indices, test_size=0.2, stratify=data.y.cpu().numpy(), random_state=42)\n",
    "    val_idx, test_idx = train_test_split(test_val_idx, test_size=0.5, stratify=data.y[test_val_idx].cpu().numpy(), random_state=42)\n",
    "    train_idx = torch.tensor(train_idx, dtype=torch.long, device=device)\n",
    "    val_idx = torch.tensor(val_idx, dtype=torch.long, device=device)\n",
    "    test_idx = torch.tensor(test_idx, dtype=torch.long, device=device)\n",
    "# Initalize STIP-GCN model with hyperparameters\n",
    "    modelCombined = STIP_GCN(in_channels=data.x.size(1),hidden_channels=256, out_channels=len(data.y.unique()),edge_attr_dim=data.edge_attr.size(1)).to(device)\n",
    "    \n",
    "    print(\"\\nTraining Paper Based STIP-GCN Model Comptiple with our STKGs datset\")\n",
    "    test_acc_combined, test_top5_combined = train_model(modelCombined, data, train_idx, val_idx, test_idx, \"STIP_GCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03121ca-7a38-432c-a2c9-c6a2d6dae21a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
